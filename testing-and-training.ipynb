{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Set data directory\n",
    "data_directory = '/Users/emilyperelman/Desktop/DISfINAL/Neural-Networks-Final-Project/Data/Training'\n",
    "#https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset\n",
    "\n",
    "batch_size = 32\n",
    "img_height, img_width = 150, 150\n",
    "\n",
    "# Create a dataset from the directory\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_directory,\n",
    "    labels='inferred', #labels are generated from directory structure\n",
    "    label_mode='categorical',\n",
    "    # color_mode='rgb',\n",
    "    batch_size=batch_size, #size of batch of data\n",
    "    image_size=(img_height, img_width), #resizing image\n",
    "    # shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.15,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    data_directory,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    # color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    # shuffle=True,\n",
    "    seed=123,\n",
    "    validation_split=0.15,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "\n",
    "for images, labels in train_dataset:\n",
    "    train_X.append(images.numpy())  # Append image batch to train_X\n",
    "    train_Y.append(labels.numpy())  # Append labels batch to train_Y\n",
    "\n",
    "train_X = np.concatenate(train_X, axis=0)  # Concatenate batches along axis 0\n",
    "train_Y = np.concatenate(train_Y, axis=0)  # Concatenate label batches along axis 0\n",
    "\n",
    "\n",
    "val_X = []\n",
    "val_Y = []\n",
    "\n",
    "for images, labels in val_dataset:\n",
    "    val_X.append(images.numpy())  # Append image batch to val_X\n",
    "    val_Y.append(labels.numpy())  # Append labels batch to val_Y\n",
    "\n",
    "val_X = np.concatenate(val_X, axis=0)  # Concatenate batches along axis 0\n",
    "val_Y = np.concatenate(val_Y, axis=0)\n",
    "\n",
    "\n",
    "testing_data_directory = '/Users/emilyperelman/Desktop/DISfINAL/Neural-Networks-Final-Project/Data/Testing'\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    data_directory,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    # color_mode='rgb',\n",
    "    batch_size=batch_size,  # Use the same batch size as training\n",
    "    image_size=(img_height, img_width),  # Use the same image dimensions as training\n",
    "    # shuffle=False,  # No need to shuffle for testing\n",
    "    seed=123,\n",
    "    validation_split=None  # No splitting for testing\n",
    ")\n",
    "\n",
    "test_X = []\n",
    "test_Y = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    test_X.append(images.numpy())  # Append image batch to test_X\n",
    "    test_Y.append(labels.numpy())  # Append labels batch to test_Y\n",
    "\n",
    "test_X = np.concatenate(test_X, axis=0)  # Concatenate batches along axis 0\n",
    "test_Y = np.concatenate(test_Y, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape = [ 150, 150, 3] ),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy']) #what we did in week 4\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_X, train_Y, epochs=10, batch_size=batch_size, validation_data=(val_X, val_Y))\n",
    "\n",
    "# Evaluate the model\n",
    "#test_loss, test_acc = model.evaluate(test_X, test_Y)\n",
    "score = model.evaluate(test_X, test_Y)\n",
    "#print(f\"Test Accuracy: {test_acc}\")\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
